{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.4657097288676235,
  "eval_steps": 500,
  "global_step": 1400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03189792663476874,
      "grad_norm": 0.06406005471944809,
      "learning_rate": 6.369426751592357e-06,
      "loss": 0.5648,
      "step": 10
    },
    {
      "epoch": 0.06379585326953748,
      "grad_norm": 0.06147134304046631,
      "learning_rate": 1.2738853503184714e-05,
      "loss": 0.5365,
      "step": 20
    },
    {
      "epoch": 0.09569377990430622,
      "grad_norm": 0.05551721155643463,
      "learning_rate": 1.910828025477707e-05,
      "loss": 0.572,
      "step": 30
    },
    {
      "epoch": 0.12759170653907495,
      "grad_norm": 0.03163742646574974,
      "learning_rate": 2.5477707006369428e-05,
      "loss": 0.5437,
      "step": 40
    },
    {
      "epoch": 0.1594896331738437,
      "grad_norm": 0.02601352147758007,
      "learning_rate": 3.184713375796178e-05,
      "loss": 0.5341,
      "step": 50
    },
    {
      "epoch": 0.19138755980861244,
      "grad_norm": 0.02225732058286667,
      "learning_rate": 3.821656050955414e-05,
      "loss": 0.536,
      "step": 60
    },
    {
      "epoch": 0.22328548644338117,
      "grad_norm": 0.017283791676163673,
      "learning_rate": 4.45859872611465e-05,
      "loss": 0.5117,
      "step": 70
    },
    {
      "epoch": 0.2551834130781499,
      "grad_norm": 0.019542068243026733,
      "learning_rate": 5.0955414012738855e-05,
      "loss": 0.5094,
      "step": 80
    },
    {
      "epoch": 0.28708133971291866,
      "grad_norm": 0.016918066889047623,
      "learning_rate": 5.732484076433121e-05,
      "loss": 0.5128,
      "step": 90
    },
    {
      "epoch": 0.3189792663476874,
      "grad_norm": 0.011807217262685299,
      "learning_rate": 6.369426751592356e-05,
      "loss": 0.5103,
      "step": 100
    },
    {
      "epoch": 0.3508771929824561,
      "grad_norm": 0.014687152579426765,
      "learning_rate": 7.006369426751592e-05,
      "loss": 0.5021,
      "step": 110
    },
    {
      "epoch": 0.3827751196172249,
      "grad_norm": 0.01115312147885561,
      "learning_rate": 7.643312101910829e-05,
      "loss": 0.5211,
      "step": 120
    },
    {
      "epoch": 0.41467304625199364,
      "grad_norm": 0.017831169068813324,
      "learning_rate": 8.280254777070065e-05,
      "loss": 0.5256,
      "step": 130
    },
    {
      "epoch": 0.44657097288676234,
      "grad_norm": 0.021352078765630722,
      "learning_rate": 8.9171974522293e-05,
      "loss": 0.5049,
      "step": 140
    },
    {
      "epoch": 0.4784688995215311,
      "grad_norm": 0.02031596377491951,
      "learning_rate": 9.554140127388536e-05,
      "loss": 0.5067,
      "step": 150
    },
    {
      "epoch": 0.5103668261562998,
      "grad_norm": 0.026373740285634995,
      "learning_rate": 9.999887985219471e-05,
      "loss": 0.5121,
      "step": 160
    },
    {
      "epoch": 0.5422647527910686,
      "grad_norm": 0.027471574023365974,
      "learning_rate": 9.997896750961429e-05,
      "loss": 0.5098,
      "step": 170
    },
    {
      "epoch": 0.5741626794258373,
      "grad_norm": 0.025078020989894867,
      "learning_rate": 9.993417440382311e-05,
      "loss": 0.5093,
      "step": 180
    },
    {
      "epoch": 0.6060606060606061,
      "grad_norm": 0.02777671627700329,
      "learning_rate": 9.986452283393452e-05,
      "loss": 0.5159,
      "step": 190
    },
    {
      "epoch": 0.6379585326953748,
      "grad_norm": 0.02330360934138298,
      "learning_rate": 9.977004747421857e-05,
      "loss": 0.4929,
      "step": 200
    },
    {
      "epoch": 0.6698564593301436,
      "grad_norm": 0.03551899641752243,
      "learning_rate": 9.965079535684042e-05,
      "loss": 0.5027,
      "step": 210
    },
    {
      "epoch": 0.7017543859649122,
      "grad_norm": 0.04089633747935295,
      "learning_rate": 9.950682584844652e-05,
      "loss": 0.4998,
      "step": 220
    },
    {
      "epoch": 0.733652312599681,
      "grad_norm": 0.05108688026666641,
      "learning_rate": 9.933821062061049e-05,
      "loss": 0.4911,
      "step": 230
    },
    {
      "epoch": 0.7655502392344498,
      "grad_norm": 0.03861409053206444,
      "learning_rate": 9.914503361415316e-05,
      "loss": 0.5064,
      "step": 240
    },
    {
      "epoch": 0.7974481658692185,
      "grad_norm": 0.06235475093126297,
      "learning_rate": 9.89273909973548e-05,
      "loss": 0.5149,
      "step": 250
    },
    {
      "epoch": 0.8293460925039873,
      "grad_norm": 0.07182417809963226,
      "learning_rate": 9.868539111808019e-05,
      "loss": 0.4801,
      "step": 260
    },
    {
      "epoch": 0.861244019138756,
      "grad_norm": 0.07887202501296997,
      "learning_rate": 9.841915444984036e-05,
      "loss": 0.4705,
      "step": 270
    },
    {
      "epoch": 0.8931419457735247,
      "grad_norm": 0.13933725655078888,
      "learning_rate": 9.812881353181789e-05,
      "loss": 0.4791,
      "step": 280
    },
    {
      "epoch": 0.9250398724082934,
      "grad_norm": 0.11628321558237076,
      "learning_rate": 9.781451290288566e-05,
      "loss": 0.4699,
      "step": 290
    },
    {
      "epoch": 0.9569377990430622,
      "grad_norm": 0.174207866191864,
      "learning_rate": 9.747640902965184e-05,
      "loss": 0.4644,
      "step": 300
    },
    {
      "epoch": 0.988835725677831,
      "grad_norm": 0.21779261529445648,
      "learning_rate": 9.71146702285669e-05,
      "loss": 0.4792,
      "step": 310
    },
    {
      "epoch": 1.0191387559808613,
      "grad_norm": 0.2632182836532593,
      "learning_rate": 9.672947658213163e-05,
      "loss": 0.4488,
      "step": 320
    },
    {
      "epoch": 1.0510366826156299,
      "grad_norm": 0.21099816262722015,
      "learning_rate": 9.632101984924749e-05,
      "loss": 0.4518,
      "step": 330
    },
    {
      "epoch": 1.0829346092503986,
      "grad_norm": 0.5118665099143982,
      "learning_rate": 9.58895033697544e-05,
      "loss": 0.4562,
      "step": 340
    },
    {
      "epoch": 1.1148325358851674,
      "grad_norm": 0.3226892948150635,
      "learning_rate": 9.543514196320311e-05,
      "loss": 0.4283,
      "step": 350
    },
    {
      "epoch": 1.1499202551834131,
      "grad_norm": 0.32780906558036804,
      "learning_rate": 9.495816182191277e-05,
      "loss": 0.4377,
      "step": 360
    },
    {
      "epoch": 1.1818181818181819,
      "grad_norm": 0.5782411098480225,
      "learning_rate": 9.445880039836675e-05,
      "loss": 0.4259,
      "step": 370
    },
    {
      "epoch": 1.2137161084529506,
      "grad_norm": 0.444623202085495,
      "learning_rate": 9.393730628700294e-05,
      "loss": 0.4351,
      "step": 380
    },
    {
      "epoch": 1.2456140350877192,
      "grad_norm": 0.6241810917854309,
      "learning_rate": 9.33939391004574e-05,
      "loss": 0.4124,
      "step": 390
    },
    {
      "epoch": 1.277511961722488,
      "grad_norm": 0.47568604350090027,
      "learning_rate": 9.282896934032264e-05,
      "loss": 0.4001,
      "step": 400
    },
    {
      "epoch": 1.3094098883572567,
      "grad_norm": 0.8296976089477539,
      "learning_rate": 9.224267826248536e-05,
      "loss": 0.4155,
      "step": 410
    },
    {
      "epoch": 1.3413078149920254,
      "grad_norm": 0.671517014503479,
      "learning_rate": 9.163535773711032e-05,
      "loss": 0.413,
      "step": 420
    },
    {
      "epoch": 1.3732057416267942,
      "grad_norm": 0.5984707474708557,
      "learning_rate": 9.100731010334008e-05,
      "loss": 0.3648,
      "step": 430
    },
    {
      "epoch": 1.405103668261563,
      "grad_norm": 0.7273867130279541,
      "learning_rate": 9.035884801878325e-05,
      "loss": 0.3927,
      "step": 440
    },
    {
      "epoch": 1.4370015948963317,
      "grad_norm": 0.619343638420105,
      "learning_rate": 8.96902943038657e-05,
      "loss": 0.347,
      "step": 450
    },
    {
      "epoch": 1.4688995215311005,
      "grad_norm": 0.8672675490379333,
      "learning_rate": 8.900198178112269e-05,
      "loss": 0.3397,
      "step": 460
    },
    {
      "epoch": 1.5007974481658692,
      "grad_norm": 1.3003908395767212,
      "learning_rate": 8.829425310951149e-05,
      "loss": 0.3372,
      "step": 470
    },
    {
      "epoch": 1.532695374800638,
      "grad_norm": 0.9345152974128723,
      "learning_rate": 8.756746061382736e-05,
      "loss": 0.3167,
      "step": 480
    },
    {
      "epoch": 1.5645933014354068,
      "grad_norm": 1.370809555053711,
      "learning_rate": 8.68219661093076e-05,
      "loss": 0.3361,
      "step": 490
    },
    {
      "epoch": 1.5964912280701755,
      "grad_norm": 1.1390653848648071,
      "learning_rate": 8.605814072151092e-05,
      "loss": 0.3042,
      "step": 500
    },
    {
      "epoch": 1.6283891547049443,
      "grad_norm": 0.7281714081764221,
      "learning_rate": 8.527636470156206e-05,
      "loss": 0.2872,
      "step": 510
    },
    {
      "epoch": 1.660287081339713,
      "grad_norm": 1.603163242340088,
      "learning_rate": 8.447702723685335e-05,
      "loss": 0.3036,
      "step": 520
    },
    {
      "epoch": 1.6921850079744818,
      "grad_norm": 1.1963658332824707,
      "learning_rate": 8.366052625729762e-05,
      "loss": 0.2641,
      "step": 530
    },
    {
      "epoch": 1.7240829346092506,
      "grad_norm": 1.3631552457809448,
      "learning_rate": 8.28272682372289e-05,
      "loss": 0.2619,
      "step": 540
    },
    {
      "epoch": 1.755980861244019,
      "grad_norm": 0.8429007530212402,
      "learning_rate": 8.197766799304943e-05,
      "loss": 0.2553,
      "step": 550
    },
    {
      "epoch": 1.7878787878787878,
      "grad_norm": 0.7073737382888794,
      "learning_rate": 8.111214847672388e-05,
      "loss": 0.2289,
      "step": 560
    },
    {
      "epoch": 1.8197767145135566,
      "grad_norm": 2.1777045726776123,
      "learning_rate": 8.023114056522335e-05,
      "loss": 0.2476,
      "step": 570
    },
    {
      "epoch": 1.8516746411483254,
      "grad_norm": 1.1113066673278809,
      "learning_rate": 7.933508284602423e-05,
      "loss": 0.2212,
      "step": 580
    },
    {
      "epoch": 1.8835725677830941,
      "grad_norm": 0.776892364025116,
      "learning_rate": 7.842442139876851e-05,
      "loss": 0.2108,
      "step": 590
    },
    {
      "epoch": 1.9154704944178629,
      "grad_norm": 1.4569591283798218,
      "learning_rate": 7.74996095731944e-05,
      "loss": 0.2348,
      "step": 600
    },
    {
      "epoch": 1.9473684210526314,
      "grad_norm": 1.2119741439819336,
      "learning_rate": 7.656110776344753e-05,
      "loss": 0.1983,
      "step": 610
    },
    {
      "epoch": 1.9792663476874002,
      "grad_norm": 0.8282471299171448,
      "learning_rate": 7.560938317888542e-05,
      "loss": 0.185,
      "step": 620
    },
    {
      "epoch": 2.0127591706539074,
      "grad_norm": 0.6015148758888245,
      "learning_rate": 7.464490961148921e-05,
      "loss": 0.2101,
      "step": 630
    },
    {
      "epoch": 2.044657097288676,
      "grad_norm": 1.1166714429855347,
      "learning_rate": 7.366816719999823e-05,
      "loss": 0.1868,
      "step": 640
    },
    {
      "epoch": 2.076555023923445,
      "grad_norm": 1.0184738636016846,
      "learning_rate": 7.26796421908851e-05,
      "loss": 0.1661,
      "step": 650
    },
    {
      "epoch": 2.1084529505582137,
      "grad_norm": 0.8668078780174255,
      "learning_rate": 7.167982669629034e-05,
      "loss": 0.1563,
      "step": 660
    },
    {
      "epoch": 2.1403508771929824,
      "grad_norm": 3.3732094764709473,
      "learning_rate": 7.066921844903666e-05,
      "loss": 0.1555,
      "step": 670
    },
    {
      "epoch": 2.172248803827751,
      "grad_norm": 1.8753724098205566,
      "learning_rate": 6.964832055484532e-05,
      "loss": 0.155,
      "step": 680
    },
    {
      "epoch": 2.20414673046252,
      "grad_norm": 0.8990037441253662,
      "learning_rate": 6.861764124187779e-05,
      "loss": 0.1601,
      "step": 690
    },
    {
      "epoch": 2.2360446570972887,
      "grad_norm": 0.931134819984436,
      "learning_rate": 6.75776936077271e-05,
      "loss": 0.1349,
      "step": 700
    },
    {
      "epoch": 2.2679425837320575,
      "grad_norm": 0.5189907550811768,
      "learning_rate": 6.65289953639853e-05,
      "loss": 0.1331,
      "step": 710
    },
    {
      "epoch": 2.2998405103668262,
      "grad_norm": 0.94588303565979,
      "learning_rate": 6.547206857851374e-05,
      "loss": 0.1398,
      "step": 720
    },
    {
      "epoch": 2.331738437001595,
      "grad_norm": 1.3005396127700806,
      "learning_rate": 6.440743941554492e-05,
      "loss": 0.1191,
      "step": 730
    },
    {
      "epoch": 2.3636363636363638,
      "grad_norm": 0.8972554802894592,
      "learning_rate": 6.333563787374493e-05,
      "loss": 0.1407,
      "step": 740
    },
    {
      "epoch": 2.3955342902711325,
      "grad_norm": 1.0115430355072021,
      "learning_rate": 6.225719752236694e-05,
      "loss": 0.1228,
      "step": 750
    },
    {
      "epoch": 2.4274322169059013,
      "grad_norm": 0.5855395197868347,
      "learning_rate": 6.117265523562737e-05,
      "loss": 0.1337,
      "step": 760
    },
    {
      "epoch": 2.45933014354067,
      "grad_norm": 0.8513731360435486,
      "learning_rate": 6.008255092543668e-05,
      "loss": 0.1273,
      "step": 770
    },
    {
      "epoch": 2.4912280701754383,
      "grad_norm": 0.6553858518600464,
      "learning_rate": 5.898742727261775e-05,
      "loss": 0.121,
      "step": 780
    },
    {
      "epoch": 2.523125996810207,
      "grad_norm": 0.9246692657470703,
      "learning_rate": 5.788782945674611e-05,
      "loss": 0.1067,
      "step": 790
    },
    {
      "epoch": 2.555023923444976,
      "grad_norm": 0.5788927674293518,
      "learning_rate": 5.6784304884746075e-05,
      "loss": 0.1233,
      "step": 800
    },
    {
      "epoch": 2.5869218500797446,
      "grad_norm": 0.4196538031101227,
      "learning_rate": 5.5677402918378e-05,
      "loss": 0.1094,
      "step": 810
    },
    {
      "epoch": 2.6188197767145134,
      "grad_norm": 0.6116708517074585,
      "learning_rate": 5.456767460075254e-05,
      "loss": 0.1147,
      "step": 820
    },
    {
      "epoch": 2.650717703349282,
      "grad_norm": 0.4253524839878082,
      "learning_rate": 5.3455672382007706e-05,
      "loss": 0.1158,
      "step": 830
    },
    {
      "epoch": 2.682615629984051,
      "grad_norm": 0.3029906153678894,
      "learning_rate": 5.234194984428562e-05,
      "loss": 0.1119,
      "step": 840
    },
    {
      "epoch": 2.7145135566188197,
      "grad_norm": 0.327118843793869,
      "learning_rate": 5.122706142614562e-05,
      "loss": 0.1186,
      "step": 850
    },
    {
      "epoch": 2.7464114832535884,
      "grad_norm": 0.30323830246925354,
      "learning_rate": 5.0111562146551085e-05,
      "loss": 0.108,
      "step": 860
    },
    {
      "epoch": 2.778309409888357,
      "grad_norm": 0.24349640309810638,
      "learning_rate": 4.8996007328567315e-05,
      "loss": 0.0951,
      "step": 870
    },
    {
      "epoch": 2.810207336523126,
      "grad_norm": 0.3561898171901703,
      "learning_rate": 4.788095232290793e-05,
      "loss": 0.1182,
      "step": 880
    },
    {
      "epoch": 2.8421052631578947,
      "grad_norm": 0.2971147298812866,
      "learning_rate": 4.676695223146776e-05,
      "loss": 0.1004,
      "step": 890
    },
    {
      "epoch": 2.8740031897926634,
      "grad_norm": 0.292475163936615,
      "learning_rate": 4.565456163097921e-05,
      "loss": 0.1094,
      "step": 900
    },
    {
      "epoch": 2.905901116427432,
      "grad_norm": 0.23141483962535858,
      "learning_rate": 4.4544334296930394e-05,
      "loss": 0.1111,
      "step": 910
    },
    {
      "epoch": 2.937799043062201,
      "grad_norm": 0.24554312229156494,
      "learning_rate": 4.3436822927882036e-05,
      "loss": 0.0946,
      "step": 920
    },
    {
      "epoch": 2.9696969696969697,
      "grad_norm": 0.25911930203437805,
      "learning_rate": 4.233257887032045e-05,
      "loss": 0.1095,
      "step": 930
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.35830578207969666,
      "learning_rate": 4.123215184418368e-05,
      "loss": 0.1157,
      "step": 940
    },
    {
      "epoch": 3.0318979266347688,
      "grad_norm": 0.2512175440788269,
      "learning_rate": 4.0136089669197364e-05,
      "loss": 0.0869,
      "step": 950
    },
    {
      "epoch": 3.0637958532695375,
      "grad_norm": 0.24307644367218018,
      "learning_rate": 3.9044937992156516e-05,
      "loss": 0.1033,
      "step": 960
    },
    {
      "epoch": 3.0956937799043063,
      "grad_norm": 0.41814562678337097,
      "learning_rate": 3.795924001528911e-05,
      "loss": 0.1041,
      "step": 970
    },
    {
      "epoch": 3.127591706539075,
      "grad_norm": 0.3295845091342926,
      "learning_rate": 3.687953622583664e-05,
      "loss": 0.1067,
      "step": 980
    },
    {
      "epoch": 3.159489633173844,
      "grad_norm": 0.20286589860916138,
      "learning_rate": 3.580636412698614e-05,
      "loss": 0.092,
      "step": 990
    },
    {
      "epoch": 3.1913875598086126,
      "grad_norm": 0.2078096866607666,
      "learning_rate": 3.474025797028797e-05,
      "loss": 0.1116,
      "step": 1000
    },
    {
      "epoch": 3.2232854864433813,
      "grad_norm": 0.2319759577512741,
      "learning_rate": 3.368174848969211e-05,
      "loss": 0.1034,
      "step": 1010
    },
    {
      "epoch": 3.25518341307815,
      "grad_norm": 0.21512198448181152,
      "learning_rate": 3.263136263733573e-05,
      "loss": 0.0856,
      "step": 1020
    },
    {
      "epoch": 3.287081339712919,
      "grad_norm": 0.25634244084358215,
      "learning_rate": 3.158962332121342e-05,
      "loss": 0.1011,
      "step": 1030
    },
    {
      "epoch": 3.3189792663476876,
      "grad_norm": 0.21858780086040497,
      "learning_rate": 3.055704914486069e-05,
      "loss": 0.0985,
      "step": 1040
    },
    {
      "epoch": 3.3508771929824563,
      "grad_norm": 0.26441308856010437,
      "learning_rate": 2.953415414918033e-05,
      "loss": 0.1057,
      "step": 1050
    },
    {
      "epoch": 3.382775119617225,
      "grad_norm": 0.1869167983531952,
      "learning_rate": 2.8521447556540192e-05,
      "loss": 0.1061,
      "step": 1060
    },
    {
      "epoch": 3.414673046251994,
      "grad_norm": 0.20088759064674377,
      "learning_rate": 2.7519433517269665e-05,
      "loss": 0.0847,
      "step": 1070
    },
    {
      "epoch": 3.446570972886762,
      "grad_norm": 0.1714613139629364,
      "learning_rate": 2.6528610858681286e-05,
      "loss": 0.1054,
      "step": 1080
    },
    {
      "epoch": 3.478468899521531,
      "grad_norm": 0.1667228490114212,
      "learning_rate": 2.5549472836742083e-05,
      "loss": 0.0959,
      "step": 1090
    },
    {
      "epoch": 3.5103668261562997,
      "grad_norm": 0.22663545608520508,
      "learning_rate": 2.4582506890518718e-05,
      "loss": 0.102,
      "step": 1100
    },
    {
      "epoch": 3.5422647527910684,
      "grad_norm": 0.22783853113651276,
      "learning_rate": 2.3628194399518206e-05,
      "loss": 0.0954,
      "step": 1110
    },
    {
      "epoch": 3.574162679425837,
      "grad_norm": 0.17189784348011017,
      "learning_rate": 2.2687010444045353e-05,
      "loss": 0.09,
      "step": 1120
    },
    {
      "epoch": 3.606060606060606,
      "grad_norm": 0.29078227281570435,
      "learning_rate": 2.1759423568696003e-05,
      "loss": 0.1031,
      "step": 1130
    },
    {
      "epoch": 3.6379585326953747,
      "grad_norm": 0.18887357413768768,
      "learning_rate": 2.0845895549104066e-05,
      "loss": 0.0977,
      "step": 1140
    },
    {
      "epoch": 3.6698564593301435,
      "grad_norm": 0.1692945659160614,
      "learning_rate": 1.994688116205813e-05,
      "loss": 0.0909,
      "step": 1150
    },
    {
      "epoch": 3.7017543859649122,
      "grad_norm": 0.14024443924427032,
      "learning_rate": 1.9062827959102413e-05,
      "loss": 0.0825,
      "step": 1160
    },
    {
      "epoch": 3.733652312599681,
      "grad_norm": 0.1577121913433075,
      "learning_rate": 1.819417604373454e-05,
      "loss": 0.0963,
      "step": 1170
    },
    {
      "epoch": 3.7655502392344498,
      "grad_norm": 0.3046141266822815,
      "learning_rate": 1.7341357852311174e-05,
      "loss": 0.1202,
      "step": 1180
    },
    {
      "epoch": 3.7974481658692185,
      "grad_norm": 0.1953357458114624,
      "learning_rate": 1.6504797938770468e-05,
      "loss": 0.1103,
      "step": 1190
    },
    {
      "epoch": 3.8293460925039873,
      "grad_norm": 0.2183164358139038,
      "learning_rate": 1.568491276327873e-05,
      "loss": 0.1109,
      "step": 1200
    },
    {
      "epoch": 3.861244019138756,
      "grad_norm": 0.14161865413188934,
      "learning_rate": 1.4882110484906232e-05,
      "loss": 0.0933,
      "step": 1210
    },
    {
      "epoch": 3.893141945773525,
      "grad_norm": 0.153842955827713,
      "learning_rate": 1.4096790758435535e-05,
      "loss": 0.0795,
      "step": 1220
    },
    {
      "epoch": 3.9250398724082936,
      "grad_norm": 0.18418282270431519,
      "learning_rate": 1.3329344535403526e-05,
      "loss": 0.0858,
      "step": 1230
    },
    {
      "epoch": 3.9569377990430623,
      "grad_norm": 0.1953045129776001,
      "learning_rate": 1.2580153869476025e-05,
      "loss": 0.093,
      "step": 1240
    },
    {
      "epoch": 3.988835725677831,
      "grad_norm": 0.1582958996295929,
      "learning_rate": 1.184959172625214e-05,
      "loss": 0.0798,
      "step": 1250
    },
    {
      "epoch": 4.019138755980861,
      "grad_norm": 0.19008266925811768,
      "learning_rate": 1.113802179759268e-05,
      "loss": 0.0893,
      "step": 1260
    },
    {
      "epoch": 4.05103668261563,
      "grad_norm": 0.14840289950370789,
      "learning_rate": 1.0445798320565464e-05,
      "loss": 0.0928,
      "step": 1270
    },
    {
      "epoch": 4.082934609250398,
      "grad_norm": 0.15093228220939636,
      "learning_rate": 9.773265901097333e-06,
      "loss": 0.0867,
      "step": 1280
    },
    {
      "epoch": 4.114832535885167,
      "grad_norm": 0.17867588996887207,
      "learning_rate": 9.12075934242082e-06,
      "loss": 0.0879,
      "step": 1290
    },
    {
      "epoch": 4.146730462519936,
      "grad_norm": 0.14498409628868103,
      "learning_rate": 8.488603478400802e-06,
      "loss": 0.0869,
      "step": 1300
    },
    {
      "epoch": 4.178628389154705,
      "grad_norm": 0.15053915977478027,
      "learning_rate": 7.877113011824262e-06,
      "loss": 0.0905,
      "step": 1310
    },
    {
      "epoch": 4.2105263157894735,
      "grad_norm": 0.14870646595954895,
      "learning_rate": 7.286592357733385e-06,
      "loss": 0.102,
      "step": 1320
    },
    {
      "epoch": 4.242424242424242,
      "grad_norm": 0.14773619174957275,
      "learning_rate": 6.717335491880377e-06,
      "loss": 0.0984,
      "step": 1330
    },
    {
      "epoch": 4.274322169059011,
      "grad_norm": 0.14656870067119598,
      "learning_rate": 6.169625804378909e-06,
      "loss": 0.1111,
      "step": 1340
    },
    {
      "epoch": 4.30622009569378,
      "grad_norm": 0.1461581289768219,
      "learning_rate": 5.643735958625646e-06,
      "loss": 0.0881,
      "step": 1350
    },
    {
      "epoch": 4.3381180223285485,
      "grad_norm": 0.21391771733760834,
      "learning_rate": 5.139927755561663e-06,
      "loss": 0.095,
      "step": 1360
    },
    {
      "epoch": 4.370015948963317,
      "grad_norm": 0.12003152072429657,
      "learning_rate": 4.658452003341424e-06,
      "loss": 0.1122,
      "step": 1370
    },
    {
      "epoch": 4.401913875598086,
      "grad_norm": 0.1432826817035675,
      "learning_rate": 4.199548392474356e-06,
      "loss": 0.0849,
      "step": 1380
    },
    {
      "epoch": 4.433811802232855,
      "grad_norm": 0.13945189118385315,
      "learning_rate": 3.763445376500968e-06,
      "loss": 0.0919,
      "step": 1390
    },
    {
      "epoch": 4.4657097288676235,
      "grad_norm": 0.13132338225841522,
      "learning_rate": 3.350360058263058e-06,
      "loss": 0.0824,
      "step": 1400
    }
  ],
  "logging_steps": 10,
  "max_steps": 1565,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.809293595041176e+19,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
